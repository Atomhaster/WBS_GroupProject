{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, random\n",
    "\n",
    "from modules.painting import painting\n",
    "from modules.database import database as db\n",
    "from modules.model_visualization import visualize\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import (Dropout, Flatten, Dense, Activation)\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import (RandomFlip, RandomRotation, Input, BatchNormalization, \n",
    "                          RandomTranslation, RandomZoom)\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "\n",
    "from tensorflow import unique_with_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Control Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting path variables for Working Directory and folder to save and load\n",
    "#   models from.\n",
    "wd = os.getcwd()\n",
    "WD_PATH =  os.path.abspath(wd)\n",
    "PATH_TRAINING = os.path.join(WD_PATH, \"model_training\")\n",
    "\n",
    "# # initializing the database object\n",
    "gallery = db()\n",
    "\n",
    "# Size of the pictures when reduced in size\n",
    "PIXEL_SIZE = 256\n",
    "\n",
    "# the proportions to split the available paintings in training\n",
    "# and testing.\n",
    "keep_unused = 10\n",
    "prop_train = 0.8\n",
    "prop_test = 0.2\n",
    "\n",
    "# selection  of artists to use. (our ids)\n",
    "# 3,4,10 = Pierre-Auguste Renoir, Francisco Goya, Paul Gauguin\n",
    "artists = [3,4,10]\n",
    "count_artists = len(artists)\n",
    "\n",
    "# defining labels in a list\n",
    "class_names = []\n",
    "for k in artists:\n",
    "    class_names.append(gallery.get_artist(k)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[336 291 311]\n"
     ]
    }
   ],
   "source": [
    "# checking the available paintings per artist.\n",
    "num_paintings = np.zeros(count_artists,np.int16)\n",
    "for j in range(count_artists):\n",
    "    num_paintings[j] = len(gallery.get_paintingids_from_artist(artists[j]))\n",
    "print(num_paintings)\n",
    "# Total number of paintings available\n",
    "TOTAL_PAINTINGS = sum(num_paintings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2.7916666666666665, 1: 3.223367697594502, 2: 3.0160771704180065}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights for the model:\n",
    "class_temp = TOTAL_PAINTINGS / num_paintings\n",
    "class_weights = {}\n",
    "for i in range(count_artists):\n",
    "    class_weights[i] = class_temp[i]\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train paintings: 724\n",
      "total test paintings: 181\n"
     ]
    }
   ],
   "source": [
    "# coding the sizes needed as collection arrays for the input data\n",
    "SIZE_P_TRAINING = 0\n",
    "training_size_paintings = num_paintings.copy()\n",
    "SIZE_P_TESTING = 0\n",
    "testing_size_paintings = num_paintings.copy()\n",
    "for i in range(count_artists):\n",
    "    train_count = int((num_paintings[i] - keep_unused)  * prop_train)\n",
    "    test_count = int((num_paintings[i] - keep_unused)  * prop_test)\n",
    "    # print(sum((train_count,test_count,10)),training_size_paintings[i])\n",
    "    SIZE_P_TRAINING += train_count\n",
    "    SIZE_P_TESTING += test_count\n",
    "    training_size_paintings[i] = train_count\n",
    "    testing_size_paintings[i] = test_count\n",
    "print(\"total train paintings:\", SIZE_P_TRAINING)\n",
    "print(\"total test paintings:\", SIZE_P_TESTING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(724, 256, 256, 3)\n",
      "(181, 256, 256, 3)\n",
      "(724, 3)\n",
      "(181, 3)\n",
      "(33,)\n"
     ]
    }
   ],
   "source": [
    "## creating arrays to hold the pictures taken from the DB\n",
    "training_images = np.zeros((SIZE_P_TRAINING,PIXEL_SIZE,PIXEL_SIZE,3))\n",
    "index_training = 0\n",
    "skip_count_training = 0\n",
    "testing_images = np.zeros((SIZE_P_TESTING,PIXEL_SIZE,PIXEL_SIZE,3))\n",
    "index_testing = 0\n",
    "skip_count_testing = 0\n",
    "# creating the arrays to hold labels. In this case they are the artist ids.\n",
    "training_labels = np.zeros((SIZE_P_TRAINING,count_artists),dtype=int)\n",
    "testing_labels = np.zeros((SIZE_P_TESTING,count_artists),dtype=int)\n",
    "unused_paintings = np.array(\n",
    "    [0]*(TOTAL_PAINTINGS-SIZE_P_TESTING-SIZE_P_TRAINING)\n",
    "    ,dtype=int)\n",
    "# checking if the numbers add up.\n",
    "print(training_images.shape)\n",
    "print(testing_images.shape)\n",
    "print(training_labels.shape)\n",
    "print(testing_labels.shape)\n",
    "print(unused_paintings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over the artists and adding randomized pictures of them to the <br>\n",
    "training and testing sets. There are also ids collected, which are unused, <br>\n",
    "so that they can be used as \"new, unseen\" input for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Artist\n",
      "New Artist\n",
      "New Artist\n"
     ]
    }
   ],
   "source": [
    "# filling the arrays with picture arrays. They will be resized according\n",
    "# to the pixel_size value\n",
    "unused_index = 0\n",
    "for i in range(count_artists):\n",
    "    # loading all ids from the artist\n",
    "    ids = gallery.get_paintingids_from_artist(artists[i])\n",
    "    # shuffle the ids to get random order for selection\n",
    "    random.seed(1983)\n",
    "    random.shuffle(ids)\n",
    "    print(\"New Artist\")\n",
    "    \n",
    "    # getting the numbers for the current artist:\n",
    "    _str = training_size_paintings[i]\n",
    "    _ste = testing_size_paintings[i]\n",
    "    # slicing the ids for training and testing of artist with id i+1\n",
    "    ids_training = ids[ : _str]\n",
    "    ids_testing = ids[_str : _str + _ste]\n",
    "    ids_unused = ids[ _str + _ste : ]\n",
    "    \n",
    "    # collecting the ids of the unused paintings\n",
    "    for l, f in zip(range(unused_index,unused_index+len(ids_unused))\n",
    "                    , ids_unused):\n",
    "        unused_paintings[l] = f[0]\n",
    "    unused_index += len(ids_unused)\n",
    "    \n",
    "    # retrieving the paintings from the db, resizing them and collecting\n",
    "    # them in the training_images array while also filling the labels\n",
    "    for k in ids_training:\n",
    "        temp_p = painting(\"local DB\", id=k[0])\n",
    "        temp_p_res = cv.resize(temp_p.ndarray, dsize=(PIXEL_SIZE,PIXEL_SIZE)\n",
    "                               ,interpolation=cv.INTER_CUBIC)\n",
    "        if temp_p_res.shape == (PIXEL_SIZE,PIXEL_SIZE,3):\n",
    "            training_images[index_training] = temp_p_res\n",
    "            training_labels[index_training,i] = 1\n",
    "            index_training += 1\n",
    "        else:\n",
    "            skip_count_training += 1\n",
    "            \n",
    "    # retrieving the paintings from the db, resizing them and collecting\n",
    "    # them in the testing_images array while also filling the labels\n",
    "    for j in ids_testing:\n",
    "        temp_p = painting(\"local DB\", id=j[0])\n",
    "        temp_p_res = cv.resize(temp_p.ndarray, dsize=(PIXEL_SIZE,PIXEL_SIZE)\n",
    "                               ,interpolation=cv.INTER_CUBIC)\n",
    "        if temp_p_res.shape == (PIXEL_SIZE,PIXEL_SIZE,3):\n",
    "            testing_images[index_testing] = temp_p_res\n",
    "            testing_labels[index_testing,i] = 1\n",
    "            index_testing += 1\n",
    "        else:\n",
    "            skip_count_testing += 1\n",
    "\n",
    "# ## dropping the last few array positions of testing images, which where \n",
    "# ## not filled.\n",
    "testing_images = testing_images[:index_testing,:,:,:]\n",
    "testing_labels = testing_labels[:index_testing,:]\n",
    "# ## dropping the last few array positions of training images, which where \n",
    "# ## not filled.\n",
    "training_images = training_images[:index_training,:,:,:]\n",
    "training_labels = training_labels[:index_training,:]\n",
    "\n",
    "# # the pixels on an image are rescaled from 0-255 to 0-1 \n",
    "training_images, testing_images = training_images/255, testing_images/255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffeling all input data.\n",
    "index_testing = list(range(testing_images.shape[0]))\n",
    "index_training = list(range(training_images.shape[0]))\n",
    "random.seed(1983)\n",
    "random.shuffle(index_testing)\n",
    "testing_images_shuffled = testing_images.copy()\n",
    "testing_labels_shuffled = testing_labels.copy()\n",
    "for i,j in zip(index_testing, range(testing_images.shape[0])):\n",
    "    testing_images_shuffled[i] = testing_images[j]\n",
    "    testing_labels_shuffled[i] = testing_labels[j]\n",
    "\n",
    "random.shuffle(index_training)\n",
    "training_images_shuffled = training_images.copy()\n",
    "training_labels_shuffled = training_labels.copy()\n",
    "for i,j in zip(index_training, range(training_images.shape[0])):\n",
    "    training_images_shuffled[i] = training_images[j]\n",
    "    training_labels_shuffled[i] = training_labels[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking data shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(653, 256, 256, 3)\n",
      "(160, 256, 256, 3)\n",
      "(653, 3)\n",
      "(160, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "(33,)\n"
     ]
    }
   ],
   "source": [
    "print(training_images_shuffled.shape)\n",
    "print(testing_images_shuffled.shape)\n",
    "print(training_labels_shuffled.shape)\n",
    "print(testing_labels_shuffled.shape)\n",
    "print(type(training_labels_shuffled[185:200]))\n",
    "print(unused_paintings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Modelling part\n",
    "####  creating the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 0\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG19(include_top = False, weights='imagenet',\n",
    "                   classes = 10, \n",
    "                   input_shape = (PIXEL_SIZE, PIXEL_SIZE, 3))\n",
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(base_model, file=\"VGG19_base_model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer for the model. \n",
    "## data augmentation counteracting the small number of paintings\n",
    "# data_augmentation = Sequential([\n",
    "#     RandomFlip('horizontal'),\n",
    "#     RandomFlip('vertical'),\n",
    "#     RandomRotation(0.2),\n",
    "#     RandomZoom(0.1),\n",
    "#     RandomTranslation(0.1, 0.1),\n",
    "# ])\n",
    "prediction = Sequential([\n",
    "    Flatten(),\n",
    "    Dense(512),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    Dense(512),\n",
    "    Dense(count_artists, activation = 'softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model from basemodel and the other layers.\n",
    "inputs = Input(shape=(PIXEL_SIZE, PIXEL_SIZE, 3))\n",
    "# x = data_augmentation(inputs)\n",
    "# x = preprocess_input(x)\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x)\n",
    "outputs = prediction(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 256, 256, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 256, 256, 3)      0         \n",
      "                                                                 \n",
      " vgg19 (Functional)          (None, 8, 8, 512)         20024384  \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 3)                 17043971  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,068,355\n",
      "Trainable params: 17,042,947\n",
      "Non-trainable params: 20,025,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training the model\n",
    "epochs = 3\n",
    "batch_size = 16\n",
    "\n",
    "early_stopping = EarlyStopping(patience = 20, \n",
    "                               verbose = 2, \n",
    "                               restore_best_weights = True)\n",
    "    \n",
    "history = model.fit(training_images_shuffled,\n",
    "                    training_labels_shuffled,\n",
    "                    validation_data = (testing_images_shuffled\n",
    "                                       , testing_labels_shuffled),\n",
    "                    class_weight = class_weights,\n",
    "                    epochs = epochs,\n",
    "                    batch_size = batch_size,\n",
    "                    callbacks = early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(os.path.join(PATH_TRAINING,\"image_classifier_BvD_withVGG19basemodel.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.load_model(os.path.join(PATH_TRAINING,\"image_classifier_BvD_withVGG19basemodel.model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize(model, file=\"VGG19_with_categorial_output.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check one prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_painting = painting(\"local DB\",random.choice(unused_paintings))\n",
    "# print(test_painting.id)\n",
    "# test_ndarray = cv.resize(test_painting.ndarray, dsize=(PIXEL_SIZE,PIXEL_SIZE)\n",
    "#                                ,interpolation=cv.INTER_CUBIC)\n",
    "# test_ndarray = test_ndarray/255\n",
    "# temp_array = np.zeros((1,PIXEL_SIZE,PIXEL_SIZE,3))\n",
    "# print(temp_array.shape)\n",
    "# temp_array[0] = test_ndarray\n",
    "# prediction = model.predict(temp_array)\n",
    "# np.set_printoptions(suppress=True)\n",
    "# print(np.round(prediction, 4))\n",
    "# print(np.argmax(prediction))\n",
    "# index = np.argmax(prediction)\n",
    "# print(f\"Prediction is {class_names[index]}\")\n",
    "\n",
    "# art_id = gallery.get_painting(test_painting.id)[1]\n",
    "# print(\"Correct is \", gallery.get_artist(art_id)[0][1])\n",
    "\n",
    "# imgplot = plt.imshow(test_painting.ndarray)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e14a3a6e153099239264c79b5d200514d7b1165346dc721db63200c7fde2b3c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
