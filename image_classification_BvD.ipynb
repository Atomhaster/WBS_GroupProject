{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras import datasets, layers, models\n",
    "import os, random\n",
    "\n",
    "from modules.painting import painting\n",
    "from modules.database import database as db\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Control Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting path variables for Working Directory and folder to save and load\n",
    "#   models from.\n",
    "wd = os.getcwd()\n",
    "WD_PATH =  os.path.abspath(wd)\n",
    "PATH_TRAINING = os.path.join(WD_PATH, \"model_training\")\n",
    "\n",
    "# # initializing the database object\n",
    "gallery = db()\n",
    "\n",
    "# ### How many pictures should be used per artist\n",
    "TOTAL_PAINTINGS = 3971\n",
    "SIZE_TRAINING = 190\n",
    "SIZE_TESTING = 38\n",
    "SIZE_UNUSED = 3971 - ((SIZE_TESTING + SIZE_TRAINING) * 10 )\n",
    "PIXEL_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating arrays to hold the pictures taken from the DB\n",
    "testing_images = np.zeros((10*SIZE_TESTING,PIXEL_SIZE,PIXEL_SIZE,3))\n",
    "index_testing = 0\n",
    "skip_count_testing = 0\n",
    "training_images = np.zeros((10*SIZE_TRAINING,PIXEL_SIZE,PIXEL_SIZE,3))\n",
    "index_training = 0\n",
    "skip_count_training = 0\n",
    "# creating the arrays to hold labels. In this case they are the artist ids.\n",
    "# testing_labels = np.zeros((10*SIZE_TESTING,1),dtype=int)\n",
    "# training_labels = np.zeros((10*SIZE_TRAINING,1),dtype=int)\n",
    "testing_labels = np.array([0]*SIZE_TESTING*10,dtype=int)\n",
    "training_labels = np.array([0]*SIZE_TRAINING*10,dtype=int)\n",
    "unused_paintings = np.array([0]*SIZE_UNUSED,dtype=int)\n",
    "\n",
    "\n",
    "# filling the arrays with picture arrays. They will be resized according\n",
    "# to the pixel_size value\n",
    "unused_index = 0\n",
    "for i in range(1,11):\n",
    "    ids = gallery.get_paintingids_from_artist(i)\n",
    "    # random.seed(1983)\n",
    "    random.shuffle(ids)\n",
    "    ids_training = ids[ : SIZE_TRAINING]\n",
    "    ids_testing = ids[SIZE_TRAINING : SIZE_TRAINING + SIZE_TESTING]\n",
    "    ids_unused = ids[SIZE_TRAINING + SIZE_TESTING : ]\n",
    "    for l, f in zip(range(unused_index,unused_index+len(ids_unused))\n",
    "                    , ids_unused):\n",
    "        unused_paintings[l] = f[0]\n",
    "    unused_index += len(ids_unused)\n",
    "    for j in ids_testing:\n",
    "        temp_p = painting(\"local DB\", id=j[0])\n",
    "        temp_p_res = cv.resize(temp_p.ndarray, dsize=(PIXEL_SIZE,PIXEL_SIZE)\n",
    "                               ,interpolation=cv.INTER_CUBIC)\n",
    "        if temp_p_res.shape == (PIXEL_SIZE,PIXEL_SIZE,3):\n",
    "            testing_images[index_testing] = temp_p_res\n",
    "            testing_labels[index_testing] = temp_p.artist_id-1\n",
    "            # testing_labels[index_testing] = [temp_p.artist_id-1,]\n",
    "            index_testing += 1\n",
    "        else:\n",
    "            skip_count_testing += 1\n",
    "    # print(\"Testing images status\")\n",
    "    # print(index_testing)\n",
    "    # print(skip_count_testing)\n",
    "    for k in ids_training:\n",
    "        temp_p = painting(\"local DB\", id=k[0])\n",
    "        temp_p_res = cv.resize(temp_p.ndarray, dsize=(PIXEL_SIZE,PIXEL_SIZE)\n",
    "                               ,interpolation=cv.INTER_CUBIC)\n",
    "        if temp_p_res.shape == (PIXEL_SIZE,PIXEL_SIZE,3):\n",
    "            training_images[index_training] = temp_p_res\n",
    "            training_labels[index_training] = temp_p.artist_id-1\n",
    "            # training_labels[index_training] = [temp_p.artist_id-1,]\n",
    "            index_training += 1\n",
    "        else:\n",
    "            skip_count_training += 1\n",
    "    # print(\"Training images status\")\n",
    "    # print(index_training)\n",
    "    # print(skip_count_training)\n",
    "\n",
    "# ## dropping the last few array positions of testing images, which where \n",
    "# ## not filled.\n",
    "testing_images = testing_images[:index_testing,:,:,:]\n",
    "testing_labels = testing_labels[:index_testing]\n",
    "\n",
    "# # the pixels on an image are rescaled from 0-255 to 0-1 \n",
    "training_images, testing_images = training_images/255, testing_images/255 \n",
    "\n",
    "# defining labels in a list\n",
    "class_names = [i[1] for i in gallery.get_all_artists()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking data shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1900, 100, 100, 3)\n",
      "(368, 100, 100, 3)\n",
      "(1900,)\n",
      "(368,)\n"
     ]
    }
   ],
   "source": [
    "print(training_images.shape)\n",
    "print(testing_images.shape)\n",
    "print(training_labels.shape)\n",
    "print(testing_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.unique(training_labels))\n",
    "# print(type(training_labels[21]))\n",
    "# print(training_labels[21].shape)\n",
    "# print(training_labels[500])\n",
    "# print(training_labels[:,0].shape)\n",
    "# print(type(training_labels[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (2, 2), input_shape=(PIXEL_SIZE,PIXEL_SIZE,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "model.add(Conv2D(32, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "model.add(Conv2D(64, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "317/317 [==============================] - 12s 35ms/step - loss: -74911256.0000 - accuracy: 0.0937 - val_loss: -402250848.0000 - val_accuracy: 0.1005\n",
      "Epoch 2/10\n",
      "317/317 [==============================] - 11s 34ms/step - loss: -2767230720.0000 - accuracy: 0.0937 - val_loss: -7870409728.0000 - val_accuracy: 0.1005\n",
      "Epoch 3/10\n",
      "317/317 [==============================] - 10s 33ms/step - loss: -22144174080.0000 - accuracy: 0.0937 - val_loss: -47432650752.0000 - val_accuracy: 0.1005\n",
      "Epoch 4/10\n",
      "317/317 [==============================] - 11s 34ms/step - loss: -96380764160.0000 - accuracy: 0.0937 - val_loss: -175735291904.0000 - val_accuracy: 0.1005\n",
      "Epoch 5/10\n",
      "317/317 [==============================] - 10s 33ms/step - loss: -297817178112.0000 - accuracy: 0.0937 - val_loss: -490162880512.0000 - val_accuracy: 0.1005\n",
      "Epoch 6/10\n",
      "317/317 [==============================] - 10s 33ms/step - loss: -748520734720.0000 - accuracy: 0.0937 - val_loss: -1151409717248.0000 - val_accuracy: 0.1005\n",
      "Epoch 7/10\n",
      "317/317 [==============================] - 11s 35ms/step - loss: -1651741032448.0000 - accuracy: 0.0937 - val_loss: -2382350516224.0000 - val_accuracy: 0.1005\n",
      "Epoch 8/10\n",
      "317/317 [==============================] - 11s 36ms/step - loss: -3189919973376.0000 - accuracy: 0.0937 - val_loss: -4474004307968.0000 - val_accuracy: 0.1005\n",
      "Epoch 9/10\n",
      "317/317 [==============================] - 10s 32ms/step - loss: -5792458080256.0000 - accuracy: 0.0937 - val_loss: -7835134984192.0000 - val_accuracy: 0.1005\n",
      "Epoch 10/10\n",
      "317/317 [==============================] - 10s 33ms/step - loss: -9854868520960.0000 - accuracy: 0.0937 - val_loss: -12955324252160.0000 - val_accuracy: 0.1005\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_images,training_labels,batch_size=6,\n",
    "                    epochs=10,\n",
    "                    validation_data=(testing_images,testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 29ms/step - loss: -12955325300736.0000 - accuracy: 0.1005\n",
      "Loss: -12955325300736.0\n",
      "Accuracy: 0.10054347664117813\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(testing_images, testing_labels)\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(PATH_TRAINING,\"image_classifier_BvDtest.model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check one prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547\n",
      "(100, 100, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 100, 100, 3), found shape=(None, 100, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m test_ndarray \u001b[38;5;241m=\u001b[39m test_ndarray\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_ndarray\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 7\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_ndarray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# index = np.argmax(prediction)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# print(f\"Prediction is {class_names[index]}\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\BVONDE~1\\AppData\\Local\\Temp\\__autograph_generated_filetf2oqgx_.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 100, 100, 3), found shape=(None, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "test_painting = painting(\"local DB\",random.choice(unused_paintings))\n",
    "print(test_painting.id)\n",
    "test_ndarray = cv.resize(test_painting.ndarray, dsize=(PIXEL_SIZE,PIXEL_SIZE)\n",
    "                               ,interpolation=cv.INTER_CUBIC)\n",
    "test_ndarray = test_ndarray/255\n",
    "print(test_ndarray.shape)\n",
    "prediction = model.predict(test_ndarray)\n",
    "# index = np.argmax(prediction)\n",
    "# print(f\"Prediction is {class_names[index]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e14a3a6e153099239264c79b5d200514d7b1165346dc721db63200c7fde2b3c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
