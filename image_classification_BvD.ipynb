{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras import datasets, layers, models\n",
    "import os, random\n",
    "\n",
    "from modules.painting import painting\n",
    "from modules.database import database as db\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Control Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting path variables for Working Directory and folder to save and load\n",
    "#   models from.\n",
    "wd = os.getcwd()\n",
    "WD_PATH =  os.path.abspath(wd)\n",
    "PATH_TRAINING = os.path.join(WD_PATH, \"model_training\")\n",
    "\n",
    "# # initializing the database object\n",
    "gallery = db()\n",
    "\n",
    "# ### How many pictures should be used per artist\n",
    "TOTAL_PAINTINGS = 3971\n",
    "SIZE_TRAINING = 190\n",
    "SIZE_TESTING = 38\n",
    "SIZE_UNUSED = 3971 - ((SIZE_TESTING + SIZE_TRAINING) * 10 )\n",
    "PIXEL_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating arrays to hold the pictures taken from the DB\n",
    "testing_images = np.zeros((10*SIZE_TESTING,PIXEL_SIZE,PIXEL_SIZE,3))\n",
    "index_testing = 0\n",
    "skip_count_testing = 0\n",
    "training_images = np.zeros((10*SIZE_TRAINING,PIXEL_SIZE,PIXEL_SIZE,3))\n",
    "index_training = 0\n",
    "skip_count_training = 0\n",
    "# creating the arrays to hold labels. In this case they are the artist ids.\n",
    "# testing_labels = np.zeros((10*SIZE_TESTING,1),dtype=int)\n",
    "# training_labels = np.zeros((10*SIZE_TRAINING,1),dtype=int)\n",
    "testing_labels = np.array([0]*SIZE_TESTING*10,dtype=int)\n",
    "training_labels = np.array([0]*SIZE_TRAINING*10,dtype=int)\n",
    "unused_paintings = np.array([0]*SIZE_UNUSED,dtype=int)\n",
    "\n",
    "\n",
    "# filling the arrays with picture arrays. They will be resized according\n",
    "# to the pixel_size value\n",
    "unused_index = 0\n",
    "for i in range(1,11):\n",
    "    ids = gallery.get_paintingids_from_artist(i)\n",
    "    # random.seed(1983)\n",
    "    random.shuffle(ids)\n",
    "    ids_training = ids[ : SIZE_TRAINING]\n",
    "    ids_testing = ids[SIZE_TRAINING : SIZE_TRAINING + SIZE_TESTING]\n",
    "    ids_unused = ids[SIZE_TRAINING + SIZE_TESTING : ]\n",
    "    for l, f in zip(range(unused_index,unused_index+len(ids_unused))\n",
    "                    , ids_unused):\n",
    "        unused_paintings[l] = f[0]\n",
    "    unused_index += len(ids_unused)\n",
    "    for j in ids_testing:\n",
    "        temp_p = painting(\"local DB\", id=j[0])\n",
    "        temp_p_res = cv.resize(temp_p.ndarray, dsize=(PIXEL_SIZE,PIXEL_SIZE)\n",
    "                               ,interpolation=cv.INTER_CUBIC)\n",
    "        if temp_p_res.shape == (PIXEL_SIZE,PIXEL_SIZE,3):\n",
    "            testing_images[index_testing] = temp_p_res\n",
    "            testing_labels[index_testing] = temp_p.artist_id-1\n",
    "            # testing_labels[index_testing] = [temp_p.artist_id-1,]\n",
    "            index_testing += 1\n",
    "        else:\n",
    "            skip_count_testing += 1\n",
    "    # print(\"Testing images status\")\n",
    "    # print(index_testing)\n",
    "    # print(skip_count_testing)\n",
    "    for k in ids_training:\n",
    "        temp_p = painting(\"local DB\", id=k[0])\n",
    "        temp_p_res = cv.resize(temp_p.ndarray, dsize=(PIXEL_SIZE,PIXEL_SIZE)\n",
    "                               ,interpolation=cv.INTER_CUBIC)\n",
    "        if temp_p_res.shape == (PIXEL_SIZE,PIXEL_SIZE,3):\n",
    "            training_images[index_training] = temp_p_res\n",
    "            training_labels[index_training] = temp_p.artist_id-1\n",
    "            # training_labels[index_training] = [temp_p.artist_id-1,]\n",
    "            index_training += 1\n",
    "        else:\n",
    "            skip_count_training += 1\n",
    "    # print(\"Training images status\")\n",
    "    # print(index_training)\n",
    "    # print(skip_count_training)\n",
    "\n",
    "# ## dropping the last few array positions of testing images, which where \n",
    "# ## not filled.\n",
    "testing_images = testing_images[:index_testing,:,:,:]\n",
    "testing_labels = testing_labels[:index_testing]\n",
    "\n",
    "# # the pixels on an image are rescaled from 0-255 to 0-1 \n",
    "training_images, testing_images = training_images/255, testing_images/255 \n",
    "\n",
    "# defining labels in a list\n",
    "class_names = [i[1] for i in gallery.get_all_artists()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input data creation with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating arrays to hold the pictures taken from the DB\n",
    "testing_images = np.zeros((10*SIZE_TESTING,PIXEL_SIZE,PIXEL_SIZE,3))\n",
    "index_testing = 0\n",
    "skip_count_testing = 0\n",
    "training_images = np.zeros((10*SIZE_TRAINING,PIXEL_SIZE,PIXEL_SIZE,3))\n",
    "index_training = 0\n",
    "skip_count_training = 0\n",
    "# creating the arrays to hold labels. In this case they are the artist ids.\n",
    "# testing_labels = np.zeros((10*SIZE_TESTING,1),dtype=int)\n",
    "# training_labels = np.zeros((10*SIZE_TRAINING,1),dtype=int)\n",
    "testing_labels = np.array([0]*SIZE_TESTING*10,dtype=int)\n",
    "training_labels = np.array([0]*SIZE_TRAINING*10,dtype=int)\n",
    "unused_paintings = np.array([0]*SIZE_UNUSED,dtype=int)\n",
    "\n",
    "\n",
    "# filling the arrays with picture arrays. They will be resized according\n",
    "# to the pixel_size value\n",
    "unused_index = 0\n",
    "for i in range(1,11):\n",
    "    ids = gallery.get_paintingids_from_artist(i)\n",
    "    # random.seed(1983)\n",
    "    random.shuffle(ids)\n",
    "    ids_training = ids[ : SIZE_TRAINING]\n",
    "    ids_testing = ids[SIZE_TRAINING : SIZE_TRAINING + SIZE_TESTING]\n",
    "    ids_unused = ids[SIZE_TRAINING + SIZE_TESTING : ]\n",
    "    for l, f in zip(range(unused_index,unused_index+len(ids_unused))\n",
    "                    , ids_unused):\n",
    "        unused_paintings[l] = f[0]\n",
    "    unused_index += len(ids_unused)\n",
    "    for j in ids_testing:\n",
    "        temp_p = painting(\"local DB\", id=j[0])\n",
    "        temp_p_res = cv.resize(temp_p.ndarray, dsize=(PIXEL_SIZE,PIXEL_SIZE)\n",
    "                               ,interpolation=cv.INTER_CUBIC)\n",
    "        if temp_p_res.shape == (PIXEL_SIZE,PIXEL_SIZE,3):\n",
    "            testing_images[index_testing] = temp_p_res\n",
    "            testing_labels[index_testing] = temp_p.artist_id-1\n",
    "            # testing_labels[index_testing] = [temp_p.artist_id-1,]\n",
    "            index_testing += 1\n",
    "        else:\n",
    "            skip_count_testing += 1\n",
    "    # print(\"Testing images status\")\n",
    "    # print(index_testing)\n",
    "    # print(skip_count_testing)\n",
    "    for k in ids_training:\n",
    "        temp_p = painting(\"local DB\", id=k[0])\n",
    "        temp_p_res = cv.resize(temp_p.ndarray, dsize=(PIXEL_SIZE,PIXEL_SIZE)\n",
    "                               ,interpolation=cv.INTER_CUBIC)\n",
    "        if temp_p_res.shape == (PIXEL_SIZE,PIXEL_SIZE,3):\n",
    "            training_images[index_training] = temp_p_res\n",
    "            training_labels[index_training] = temp_p.artist_id-1\n",
    "            # training_labels[index_training] = [temp_p.artist_id-1,]\n",
    "            index_training += 1\n",
    "        else:\n",
    "            skip_count_training += 1\n",
    "    # print(\"Training images status\")\n",
    "    # print(index_training)\n",
    "    # print(skip_count_training)\n",
    "\n",
    "# ## dropping the last few array positions of testing images, which where \n",
    "# ## not filled.\n",
    "testing_images = testing_images[:index_testing,:,:,:]\n",
    "testing_labels = testing_labels[:index_testing]\n",
    "\n",
    "# # the pixels on an image are rescaled from 0-255 to 0-1 \n",
    "training_images, testing_images = training_images/255, testing_images/255 \n",
    "\n",
    "# defining labels in a list\n",
    "class_names = [i[1] for i in gallery.get_all_artists()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking data shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1900, 32, 32, 3)\n",
      "(367, 32, 32, 3)\n",
      "(1900,)\n",
      "(367,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(training_images.shape)\n",
    "print(testing_images.shape)\n",
    "print(training_labels.shape)\n",
    "print(testing_labels.shape)\n",
    "print(type(training_labels[185:200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(training_labels[500:510])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.unique(training_labels))\n",
    "# print(type(training_labels[21]))\n",
    "# print(training_labels[21].shape)\n",
    "# print(training_labels[500])\n",
    "# print(training_labels[:,0].shape)\n",
    "# print(type(training_labels[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (2, 2), input_shape=(PIXEL_SIZE,PIXEL_SIZE,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "model.add(Conv2D(32, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "model.add(Conv2D(64, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## different version\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64,(3,3),padding='same',input_shape=(PIXEL_SIZE, PIXEL_SIZE , 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128,(3 , 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten ())\n",
    "  \n",
    "## fully connected layer\n",
    "for i in range(0):\n",
    "    units=256//(i+1)\n",
    "    if units<32:\n",
    "        break\n",
    "    \n",
    "    if i ==0:\n",
    "        input_dim=model.output_shape[1]\n",
    "        \n",
    "    else:\n",
    "        input_dim=units\n",
    "        \n",
    "    print(input_dim)\n",
    "    \n",
    "    # Add the Dense Layer along with activation and batch normalization\n",
    "    \n",
    "    dense_layer=Dense(units=units,input_dim=input_dim,)\n",
    "    \n",
    "    # Add the Leaky ReLU activation layer\n",
    "    \n",
    "    dense_layer=Dense(units=64,input_dim=model.output_shape[1])\n",
    "    activation_layer=Activation('relu')\n",
    "    batch_norm_layer = BatchNormalization()\n",
    "    model.add(dense_layer)\n",
    "    model.add(activation_layer)\n",
    "    model.add(batch_norm_layer)\n",
    "   \n",
    "## Add Dropout Layer\n",
    "dropout_fraction=0.5\n",
    "dropout_layer=Dropout(dropout_fraction)\n",
    "\n",
    "## Add the dense layer for final output\n",
    "dense_output=Dense(units=15, input_dim=model.output_shape[1], activation='softmax')\n",
    "# activation_output = Activation('sigmoid')\n",
    "\n",
    "model.add(dropout_layer)\n",
    "model.add(dense_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0001) # learning rate\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py\", line 2156, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\backend.py\", line 5707, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 15) vs (None, 1)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtraining_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtesting_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtesting_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\BVONDE~1\\AppData\\Local\\Temp\\__autograph_generated_filehcxd62jc.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py\", line 2156, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\backend.py\", line 5707, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 15) vs (None, 1)).\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_images,training_labels,batch_size=12,\n",
    "                    epochs=10,\n",
    "                    validation_data=(testing_images,testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy = model.evaluate(testing_images, testing_labels)\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(PATH_TRAINING,\"image_classifier_BvDtest.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model(os.path.join(PATH_TRAINING,\"image_classifier_BvDtest.model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check one prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_painting = painting(\"local DB\",random.choice(unused_paintings))\n",
    "print(test_painting.id)\n",
    "test_ndarray = cv.resize(test_painting.ndarray, dsize=(PIXEL_SIZE,PIXEL_SIZE)\n",
    "                               ,interpolation=cv.INTER_CUBIC)\n",
    "test_ndarray = test_ndarray/255\n",
    "temp_array = np.zeros((1,PIXEL_SIZE,PIXEL_SIZE,3))\n",
    "temp_array[0] = test_ndarray\n",
    "print(temp_array.shape)\n",
    "print(test_ndarray.shape)\n",
    "prediction = model.predict(temp_array)\n",
    "index = np.argmax(prediction)\n",
    "print(f\"Prediction is {class_names[index]}\")\n",
    "imgplot = plt.imshow(test_painting.ndarray)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e14a3a6e153099239264c79b5d200514d7b1165346dc721db63200c7fde2b3c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
