{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, random\n",
    "\n",
    "from modules.painting import painting\n",
    "from modules.database import database as db\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import (Dropout, Flatten, Dense, Activation)\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import (RandomFlip, RandomRotation, Input, BatchNormalization, \n",
    "                          RandomTranslation, RandomZoom)\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "\n",
    "from tensorflow import unique_with_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Control Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting path variables for Working Directory and folder to save and load\n",
    "#   models from.\n",
    "wd = os.getcwd()\n",
    "WD_PATH =  os.path.abspath(wd)\n",
    "PATH_TRAINING = os.path.join(WD_PATH, \"model_training\")\n",
    "\n",
    "# # initializing the database object\n",
    "gallery = db()\n",
    "\n",
    "# ### How many pictures should be used per artist\n",
    "TOTAL_PAINTINGS = 3971\n",
    "SIZE_TRAINING = 190\n",
    "SIZE_TESTING = 38\n",
    "SIZE_UNUSED = 3971 - ((SIZE_TESTING + SIZE_TRAINING) * 10 )\n",
    "PIXEL_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[877 439 336 291 259 239 702 262 255 311]\n"
     ]
    }
   ],
   "source": [
    "# checking the available paintings per artist.\n",
    "num_paintings = np.zeros(10,np.int16)\n",
    "for j in range(10):\n",
    "    num_paintings[j] = len(gallery.get_paintingids_from_artist(j+1))\n",
    "print(num_paintings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Artist\n",
      "Training images status\n",
      "190\n",
      "0\n",
      "New Artist\n",
      "Training images status\n",
      "372\n",
      "8\n",
      "New Artist\n",
      "Training images status\n",
      "562\n",
      "8\n",
      "New Artist\n",
      "Training images status\n",
      "683\n",
      "77\n",
      "New Artist\n",
      "Training images status\n",
      "872\n",
      "78\n",
      "New Artist\n",
      "Training images status\n",
      "1061\n",
      "79\n",
      "New Artist\n",
      "Training images status\n",
      "1251\n",
      "79\n",
      "New Artist\n",
      "Training images status\n",
      "1441\n",
      "79\n",
      "New Artist\n",
      "Training images status\n",
      "1630\n",
      "80\n",
      "New Artist\n",
      "Training images status\n",
      "1820\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "## creating arrays to hold the pictures taken from the DB\n",
    "testing_images = np.zeros((10*SIZE_TESTING,PIXEL_SIZE,PIXEL_SIZE,3))\n",
    "index_testing = 0\n",
    "skip_count_testing = 0\n",
    "training_images = np.zeros((10*SIZE_TRAINING,PIXEL_SIZE,PIXEL_SIZE,3))\n",
    "index_training = 0\n",
    "skip_count_training = 0\n",
    "# creating the arrays to hold labels. In this case they are the artist ids.\n",
    "# testing_labels = np.zeros((10*SIZE_TESTING,1),dtype=int)\n",
    "# training_labels = np.zeros((10*SIZE_TRAINING,1),dtype=int)\n",
    "testing_labels = np.array([0]*SIZE_TESTING*10,dtype=int)\n",
    "training_labels = np.array([0]*SIZE_TRAINING*10,dtype=int)\n",
    "unused_paintings = np.array([0]*SIZE_UNUSED,dtype=int)\n",
    "\n",
    "\n",
    "# filling the arrays with picture arrays. They will be resized according\n",
    "# to the pixel_size value\n",
    "unused_index = 0\n",
    "for i in range(1,11):\n",
    "    ids = gallery.get_paintingids_from_artist(i)\n",
    "    # random.seed(1983)\n",
    "    random.shuffle(ids)\n",
    "    print(\"New Artist\")\n",
    "    ids_training = ids[ : SIZE_TRAINING]\n",
    "    # print(len(ids_training))\n",
    "    ids_testing = ids[SIZE_TRAINING : SIZE_TRAINING + SIZE_TESTING]\n",
    "    \n",
    "    # print(len(ids_testing))\n",
    "    ids_unused = ids[SIZE_TRAINING + SIZE_TESTING : ]\n",
    "    # print(len(ids_unused))\n",
    "    ##  Größen der arrays correct\n",
    "    # print(\"start:\", unused_index)\n",
    "    # print(\"end :\", unused_index+len(ids_unused))\n",
    "    for l, f in zip(range(unused_index,unused_index+len(ids_unused))\n",
    "                    , ids_unused):\n",
    "        unused_paintings[l] = f[0]\n",
    "    unused_index += len(ids_unused)\n",
    "    # print(\"After adding the Artist\", unused_index)\n",
    "    # print(unused_paintings.shape)\n",
    "    for j in ids_testing:\n",
    "        temp_p = painting(\"local DB\", id=j[0])\n",
    "        temp_p_res = cv.resize(temp_p.ndarray, dsize=(PIXEL_SIZE,PIXEL_SIZE)\n",
    "                               ,interpolation=cv.INTER_CUBIC)\n",
    "        if temp_p_res.shape == (PIXEL_SIZE,PIXEL_SIZE,3):\n",
    "            testing_images[index_testing] = temp_p_res\n",
    "            testing_labels[index_testing] = temp_p.artist_id-1\n",
    "            # testing_labels[index_testing] = [temp_p.artist_id-1,]\n",
    "            index_testing += 1\n",
    "        else:\n",
    "            skip_count_testing += 1\n",
    "    # print(\"Testing images status\")\n",
    "    # print(index_testing)\n",
    "    # print(skip_count_testing)\n",
    "    for k in ids_training:\n",
    "        temp_p = painting(\"local DB\", id=k[0])\n",
    "        temp_p_res = cv.resize(temp_p.ndarray, dsize=(PIXEL_SIZE,PIXEL_SIZE)\n",
    "                               ,interpolation=cv.INTER_CUBIC)\n",
    "        if temp_p_res.shape == (PIXEL_SIZE,PIXEL_SIZE,3):\n",
    "            training_images[index_training] = temp_p_res\n",
    "            training_labels[index_training] = temp_p.artist_id-1\n",
    "            # training_labels[index_training] = [temp_p.artist_id-1,]\n",
    "            index_training += 1\n",
    "        else:\n",
    "            skip_count_training += 1\n",
    "    print(\"Training images status\")\n",
    "    print(index_training)\n",
    "    print(skip_count_training)\n",
    "\n",
    "# ## dropping the last few array positions of testing images, which where \n",
    "# ## not filled.\n",
    "testing_images = testing_images[:index_testing,:,:,:]\n",
    "testing_labels = testing_labels[:index_testing]\n",
    "# ## dropping the last few array positions of training images, which where \n",
    "# ## not filled.\n",
    "training_images = training_images[:index_training,:,:,:]\n",
    "training_labels = training_labels[:index_training]\n",
    "\n",
    "# # the pixels on an image are rescaled from 0-255 to 0-1 \n",
    "training_images, testing_images = training_images/255, testing_images/255 \n",
    "\n",
    "# defining labels in a list\n",
    "class_names = [i[1] for i in gallery.get_all_artists()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking data shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1820, 128, 128, 3)\n",
      "(362, 128, 128, 3)\n",
      "(1820,)\n",
      "(362,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(training_images.shape)\n",
    "print(testing_images.shape)\n",
    "print(training_labels.shape)\n",
    "print(testing_labels.shape)\n",
    "print(type(training_labels[185:200]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Creating the weight vector for the artists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking data counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tl, idx_tl, count_tl = unique_with_counts(training_labels)\n",
    "y_testl, idx_testl, count_testl = unique_with_counts(testing_labels)\n",
    "y_unused, idx_unused, count_unused = unique_with_counts(unused_paintings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32) tf.Tensor([190 182 190 121 189 189 190 190 189 190], shape=(10,), dtype=int32)\n",
      "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32) tf.Tensor([37 36 38 25 38 36 38 38 38 38], shape=(10,), dtype=int32)\n",
      "tf.Tensor([1691], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(y_tl, count_tl)\n",
    "print(y_testl, count_testl)\n",
    "print(unique_with_counts(count_unused)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Modelling part\n",
    "####  creating the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 0\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG19(include_top = False,\n",
    "                   classes = 10, \n",
    "                   input_shape = (PIXEL_SIZE, PIXEL_SIZE, 3))\n",
    "\n",
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer for the model. \n",
    "## data augmentation counteracting the small number of paintings\n",
    "data_augmentation = Sequential([\n",
    "    RandomFlip('horizontal'),\n",
    "    RandomFlip('vertical'),\n",
    "    RandomRotation(0.2),\n",
    "    RandomZoom(0.1),\n",
    "    RandomTranslation(0.1, 0.1),\n",
    "])\n",
    "prediction = Sequential([\n",
    "    Flatten(),\n",
    "    Dense(512),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    Dense(512),\n",
    "    Dense(10, activation = 'softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model from basemodel and the other layers.\n",
    "inputs = Input(shape=(PIXEL_SIZE, PIXEL_SIZE, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x)\n",
    "outputs = prediction(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem_1   (None, 128, 128, 3)      0         \n",
      " (SlicingOpLambda)                                               \n",
      "                                                                 \n",
      " tf.nn.bias_add_1 (TFOpLambd  (None, 128, 128, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " vgg19 (Functional)          (None, 4, 4, 512)         20024384  \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   (None, 10)                4464650   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,489,034\n",
      "Trainable params: 4,463,626\n",
      "Non-trainable params: 20,025,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "114/114 [==============================] - 76s 666ms/step - loss: 2.6014 - accuracy: 0.2505 - val_loss: 32.7918 - val_accuracy: 0.1050\n",
      "Epoch 2/100\n",
      "114/114 [==============================] - 76s 671ms/step - loss: 2.3821 - accuracy: 0.2681 - val_loss: 28.2884 - val_accuracy: 0.1050\n",
      "Epoch 3/100\n",
      "114/114 [==============================] - 77s 680ms/step - loss: 2.1361 - accuracy: 0.2945 - val_loss: 24.3743 - val_accuracy: 0.1243\n",
      "Epoch 4/100\n",
      "114/114 [==============================] - 76s 669ms/step - loss: 2.2124 - accuracy: 0.2824 - val_loss: 72.9142 - val_accuracy: 0.1050\n",
      "Epoch 5/100\n",
      "114/114 [==============================] - 79s 694ms/step - loss: 2.0901 - accuracy: 0.2896 - val_loss: 29.5103 - val_accuracy: 0.1050\n",
      "Epoch 6/100\n",
      "114/114 [==============================] - 78s 688ms/step - loss: 1.9886 - accuracy: 0.3016 - val_loss: 25.2036 - val_accuracy: 0.1050\n",
      "Epoch 7/100\n",
      "  4/114 [>.............................] - ETA: 1:01 - loss: 2.2965 - accuracy: 0.1875"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[0;32m      5\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, \n\u001b[0;32m      6\u001b[0m                                verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, \n\u001b[0;32m      7\u001b[0m                                restore_best_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 9\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtraining_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtesting_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesting_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# class_weight = class_weights,\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\bvondewitz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## training the model\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "\n",
    "early_stopping = EarlyStopping(patience = 20, \n",
    "                               verbose = 2, \n",
    "                               restore_best_weights = True)\n",
    "    \n",
    "history = model.fit(training_images,\n",
    "                    training_labels,\n",
    "                    validation_data = (testing_images, testing_labels),\n",
    "                    # class_weight = class_weights,\n",
    "                    epochs = epochs,\n",
    "                    batch_size = batch_size,\n",
    "                    callbacks = early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(PATH_TRAINING,\"image_classifier_BvD_withVGG19basemodel.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model(os.path.join(PATH_TRAINING,\"image_classifier_BvD_withVGG19basemodel.model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check one prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_painting = painting(\"local DB\",random.choice(unused_paintings))\n",
    "print(test_painting.id)\n",
    "test_ndarray = cv.resize(test_painting.ndarray, dsize=(PIXEL_SIZE,PIXEL_SIZE)\n",
    "                               ,interpolation=cv.INTER_CUBIC)\n",
    "test_ndarray = test_ndarray/255\n",
    "temp_array = np.zeros((1,PIXEL_SIZE,PIXEL_SIZE,3))\n",
    "print(temp_array.shape)\n",
    "temp_array[0] = test_ndarray\n",
    "prediction = model.predict(temp_array)\n",
    "np.set_printoptions(suppress=True)\n",
    "print(np.round(prediction, 4))\n",
    "print(np.argmax(prediction))\n",
    "index = np.argmax(prediction)\n",
    "print(f\"Prediction is {class_names[index]}\")\n",
    "imgplot = plt.imshow(test_painting.ndarray)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e14a3a6e153099239264c79b5d200514d7b1165346dc721db63200c7fde2b3c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
